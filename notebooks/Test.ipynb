{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.parent = None\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, child):\n",
    "        child.parent = self\n",
    "        self.children.append(child)\n",
    "\n",
    "def spacy_doc_to_tree(doc):\n",
    "    # Create a TreeNode for each token in the doc\n",
    "    nodes = [TreeNode(token) for token in doc]\n",
    "\n",
    "    # Create the tree structure by connecting parent-child relationships\n",
    "    for token, node in zip(doc, nodes):\n",
    "        if token.head.i == token.i:  # Skip root node (head is itself)\n",
    "            continue\n",
    "        parent_node = nodes[token.head.i]\n",
    "        parent_node.add_child(node)\n",
    "\n",
    "    # Find and return the root node\n",
    "    root = next(node for node in nodes if node.parent is None)\n",
    "    return root\n",
    "\n",
    "\n",
    "\n",
    "def create_dataframe_from_tree(root):\n",
    "    if not root:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Data list to hold information about each node\n",
    "    data = []\n",
    "    queue = deque([(root, 0, None)])\n",
    "\n",
    "    while queue:\n",
    "        node, level, parent = queue.popleft()\n",
    "\n",
    "        # If the node has a parent, find the positions of its siblings\n",
    "        if parent:\n",
    "            sibling_positions = [child.data.i for child in parent.children]\n",
    "        else:\n",
    "            sibling_positions = []\n",
    "\n",
    "        node_data = {\n",
    "            \"word\": node.data.text,\n",
    "            \"position\": node.data.i,\n",
    "            \"level\": level,\n",
    "            \"level_weight\": 1 / (level + 1),\n",
    "            \"parent\": parent.data.text if parent else None,\n",
    "            \"sibling_positions\": sibling_positions\n",
    "        }\n",
    "        data.append(node_data)\n",
    "\n",
    "        for child in node.children:\n",
    "            queue.append((child, level + 1, node))\n",
    "\n",
    "    # Create DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(by='level')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# text = \"This is an example sentence.\"\n",
    "# doc = nlp(text)\n",
    "\n",
    "# Convert Spacy dependency tree to a Tree object\n",
    "# tree_root = spacy_doc_to_tree(doc)\n",
    "\n",
    "# Example usage with the Tree structure\n",
    "# tree_df = create_dataframe_from_tree(tree_root)\n",
    "# print(tree_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'token'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Example usage with the Tree structure\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tree_df \u001b[38;5;241m=\u001b[39m create_dataframe_from_tree(tree_root)\n\u001b[0;32m---> 10\u001b[0m tree_df \u001b[38;5;241m=\u001b[39m tree_df[\u001b[43mtree_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMASK\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m tree_df\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'token'"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"A grandpa is not living in Himalayas.\"\n",
    "doc = nlp(text+' MASK')\n",
    "\n",
    "# Convert Spacy dependency tree to a Tree object\n",
    "tree_root = spacy_doc_to_tree(doc)\n",
    "\n",
    "# Example usage with the Tree structure\n",
    "tree_df = create_dataframe_from_tree(tree_root)\n",
    "tree_df = tree_df[tree_df['token'] != 'MASK']\n",
    "tree_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>position</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4490</td>\n",
       "      <td>1</td>\n",
       "      <td>grand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8957</td>\n",
       "      <td>2</td>\n",
       "      <td>pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318</td>\n",
       "      <td>3</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>407</td>\n",
       "      <td>4</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2877</td>\n",
       "      <td>5</td>\n",
       "      <td>living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>287</td>\n",
       "      <td>6</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42438</td>\n",
       "      <td>7</td>\n",
       "      <td>Himal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>323</td>\n",
       "      <td>8</td>\n",
       "      <td>ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_id  position    token\n",
       "0         32         0        A\n",
       "1       4490         1    grand\n",
       "2       8957         2       pa\n",
       "3        318         3       is\n",
       "4        407         4      not\n",
       "5       2877         5   living\n",
       "6        287         6       in\n",
       "7      42438         7    Himal\n",
       "8        323         8       ay\n",
       "9        292         9       as\n",
       "10        13        10        ."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer('A grandpa is not living in Himalayas.')\n",
    "num_tokens = len(encoding['input_ids'])\n",
    "positions = range(num_tokens)\n",
    "df_tokens = pd.DataFrame({'token_id': encoding['input_ids'], 'position': positions})\n",
    "df_tokens['token'] = [tokenizer.decode([token_id]) for token_id in df_tokens['token_id']]\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>level</th>\n",
       "      <th>level_weight</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>living</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grandpa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>grandpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Himalayas</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  level  level_weight   parent\n",
       "0     living      0      1.000000     None\n",
       "1    grandpa      1      0.500000   living\n",
       "2         is      1      0.500000   living\n",
       "3        not      1      0.500000   living\n",
       "4         in      1      0.500000   living\n",
       "5          .      1      0.500000   living\n",
       "6          A      2      0.333333  grandpa\n",
       "7  Himalayas      2      0.333333       in"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_df = tree_df[['word', 'level', 'level_weight', 'parent']]\n",
    "tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['A', 'grandpa', 'is', 'not', 'living', 'in', 'Himalayas', '.']\n",
      "token_ids: [32, 4490, 8957, 318, 407, 2877, 287, 42438, 323, 292, 13]\n",
      "word_subtoken_dict: {'A': [32], 'grandpa': [4490, 8957], 'is': [318], 'not': [407], 'living': [2877], 'in': [287], 'Himalayas': [42438, 323, 292], '.': [13]}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Initialize tokenizer (you can replace 'bert-base-uncased' with your desired model)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Sentence combining all words\n",
    "sentence = 'A grandpa is not living in Himalayas.'\n",
    "\n",
    "def get_word_subtoken_dict(sentence, tokenizer):\n",
    "    # Tokenize the sentence to get subtokens\n",
    "    token_ids = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "\n",
    "    # Get words from the sentence\n",
    "    words = [t.strip() for t in re.findall(r'\\b.*?\\S.*?(?:\\b|$)', sentence)]\n",
    "\n",
    "    # Initialize dictionary to store word-subtoken mappings\n",
    "    word_subtoken_dict = {}\n",
    "    k = 0\n",
    "\n",
    "    for word in words:\n",
    "        word_len = 0\n",
    "        list_subtokens = []\n",
    "        while word_len < len(word):\n",
    "            list_subtokens.append(token_ids[k])\n",
    "            decoded_word = tokenizer.decode([token_ids[k]]).replace(' ','')\n",
    "            word_len += len(decoded_word)\n",
    "            k += 1\n",
    "        word_subtoken_dict[word] = list_subtokens\n",
    "\n",
    "    return word_subtoken_dict\n",
    "\n",
    "# Track position in the encoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2877]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_subtoken_dict['living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>level</th>\n",
       "      <th>level_weight</th>\n",
       "      <th>parent</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_x</th>\n",
       "      <th>parent_ids</th>\n",
       "      <th>position</th>\n",
       "      <th>token_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>living</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>2877</td>\n",
       "      <td>living</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grandpa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "      <td>4490</td>\n",
       "      <td>grand</td>\n",
       "      <td>[2877]</td>\n",
       "      <td>1</td>\n",
       "      <td>grand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grandpa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "      <td>8957</td>\n",
       "      <td>pa</td>\n",
       "      <td>[2877]</td>\n",
       "      <td>2</td>\n",
       "      <td>pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "      <td>318</td>\n",
       "      <td>is</td>\n",
       "      <td>[2877]</td>\n",
       "      <td>3</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "      <td>407</td>\n",
       "      <td>not</td>\n",
       "      <td>[2877]</td>\n",
       "      <td>4</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "      <td>287</td>\n",
       "      <td>in</td>\n",
       "      <td>[2877]</td>\n",
       "      <td>6</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>living</td>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>[2877]</td>\n",
       "      <td>10</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>grandpa</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>[4490, 8957]</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Himalayas</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>in</td>\n",
       "      <td>42438</td>\n",
       "      <td>Himal</td>\n",
       "      <td>[287]</td>\n",
       "      <td>7</td>\n",
       "      <td>Himal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Himalayas</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>in</td>\n",
       "      <td>323</td>\n",
       "      <td>ay</td>\n",
       "      <td>[287]</td>\n",
       "      <td>8</td>\n",
       "      <td>ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Himalayas</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>in</td>\n",
       "      <td>292</td>\n",
       "      <td>as</td>\n",
       "      <td>[287]</td>\n",
       "      <td>9</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  level  level_weight   parent  token_id  token_x    parent_ids  \\\n",
       "0      living      0      1.000000     None      2877   living           NaN   \n",
       "1     grandpa      1      0.500000   living      4490    grand        [2877]   \n",
       "2     grandpa      1      0.500000   living      8957       pa        [2877]   \n",
       "3          is      1      0.500000   living       318       is        [2877]   \n",
       "4         not      1      0.500000   living       407      not        [2877]   \n",
       "5          in      1      0.500000   living       287       in        [2877]   \n",
       "6           .      1      0.500000   living        13        .        [2877]   \n",
       "7           A      2      0.333333  grandpa        32        A  [4490, 8957]   \n",
       "8   Himalayas      2      0.333333       in     42438    Himal         [287]   \n",
       "9   Himalayas      2      0.333333       in       323       ay         [287]   \n",
       "10  Himalayas      2      0.333333       in       292       as         [287]   \n",
       "\n",
       "    position  token_y  \n",
       "0          5   living  \n",
       "1          1    grand  \n",
       "2          2       pa  \n",
       "3          3       is  \n",
       "4          4      not  \n",
       "5          6       in  \n",
       "6         10        .  \n",
       "7          0        A  \n",
       "8          7    Himal  \n",
       "9          8       ay  \n",
       "10         9       as  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def build_token_dependency_tree(tree_df, word_subtoken_dict, tokenizer, df_tokens):\n",
    "    new_rows = []\n",
    "    for index, row in tree_df.iterrows():\n",
    "        word = row['word']\n",
    "        token_ids = word_subtoken_dict[word]  # Use your tokenizer here\n",
    "        for token_id in token_ids:\n",
    "            new_row = row.copy()\n",
    "            new_row['token_id'] = token_id\n",
    "            new_row['token'] = tokenizer.decode([token_id])\n",
    "            if row['parent'] is not None:\n",
    "                new_row['parent_ids'] = word_subtoken_dict[row['parent']]\n",
    "            new_rows.append(new_row)\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    new_df = pd.merge(new_df, df_tokens, on=['token_id', 'token'], how='left')\n",
    "    return new_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
