{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MIN_TRANSFORMERS_VERSION = \"4.25.1\"\n",
    "\n",
    "# check transformers version\n",
    "assert (\n",
    "    transformers.__version__ >= MIN_TRANSFORMERS_VERSION\n",
    "), f\"Please upgrade transformers to version {MIN_TRANSFORMERS_VERSION} or higher.\"\n",
    "\n",
    "root_dir = \"/cluster/home/kamara/syntax-shap/shap2\"\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/kamara/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"#\"mistralai/Mistral-7B-v0.1\"\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\") #\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, is_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# set model decoder to true\n",
    "model.config.is_decoder = True\n",
    "# set text-generation params under task_specific_params\n",
    "model.config.task_specific_params[\"text-generation\"] = {\n",
    "    \"do_sample\": True,\n",
    "    \"max_new_tokens\": 1,\n",
    "    #\"temperature\": 0.7,\n",
    "    #\"top_k\": 50,\n",
    "    #\"no_repeat_ngram_size\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TextGeneration\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lmmodel = TextGeneration(model, tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_local_data_url = \"/cluster/home/kamara/syntax-shap/data/\"\n",
    "tsv_file = open(github_local_data_url + \"Inconsistent-Dataset-Negation.tsv\")\n",
    "read_tsv = list(csv.reader(tsv_file, delimiter=\"\\t\"))\n",
    "data = []\n",
    "for row in read_tsv:\n",
    "    data.append(row[1][:-8])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<models._text_generation.TextGeneration at 0x2aaf5d05d850>,\n",
       " GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " },\n",
       " CPUDispatcher(<function identity at 0x2aaf86a548b0>),\n",
       " True,\n",
       " 'A brother is not a')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmmodel, lmmodel.tokenizer, links.identity, True, *row_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MaskedModel\n",
    "import links\n",
    "from maskers import Text\n",
    "\n",
    "def run_model(row_args, mask, pipeline):\n",
    "    masker = Text(pipeline.tokenizer)\n",
    "    fm = MaskedModel(pipeline, masker, links.identity, True, *row_args)\n",
    "    if mask is None:\n",
    "        mask = np.ones(len(fm), dtype=bool)\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    pred = fm(mask.reshape(1, -1))[0]\n",
    "    probs = fm.probs\n",
    "    return pred, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invariants() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22396/2509826342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmasker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/syntax-shap/shap2/utils/_masked_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, masker, link, linearize_link, *args)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# if the masker supports it, save what positions vary from the background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"invariants\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvariants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variants_column_sums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             self._variants_row_inds = [\n",
      "\u001b[0;31mTypeError\u001b[0m: invariants() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "from utils import MaskedModel\n",
    "import links\n",
    "from maskers import Text\n",
    "\n",
    "row_args = ['A brother is not a','A girl is a', 'A girl is not a']\n",
    "masks = [np.array([0,0,1,1,0]), np.array([1,0,0,1]), np.array([1,1,0,1,1])]\n",
    "\n",
    "masker = Text(lmmodel.tokenizer)\n",
    "fm = MaskedModel(lmmodel, masker, links.identity, True, *row_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask [False False  True  True  True]\n",
      "row_args ('A brother is not a',)\n",
      "inputs {'input_ids': tensor([[986, 318, 407, 257]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n",
      "inputs on device cpu\n",
      "inner model on device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2372.]),\n",
       " array([0.02595965, 0.00901051, 0.01103739, 0.03134582, 0.00896156,\n",
       "        0.05045101, 0.16056432, 0.03414702, 0.01330023, 0.0353783 ,\n",
       "        0.00868273, 0.02647327, 0.01086378, 0.01837882, 0.0151232 ,\n",
       "        0.016124  , 0.01603408, 0.00792033, 0.01162166, 0.00955673,\n",
       "        0.00860327, 0.00860656, 0.00832599, 0.03357251, 0.01761645,\n",
       "        0.00852578, 0.04587767, 0.02127966, 0.0281394 , 0.03995908,\n",
       "        0.00903902, 0.00863741, 0.02917008, 0.00831799, 0.03344595,\n",
       "        0.02462728, 0.00825887, 0.0080195 , 0.01016013, 0.00841784,\n",
       "        0.0078791 , 0.01198929, 0.00878012, 0.00840533, 0.01120804,\n",
       "        0.00871405, 0.02027439, 0.01024521, 0.0110389 , 0.01193071],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_keep = fm(mask.reshape(1, -1))[0]\n",
    "pred_keep, fm.probs[fm.probs>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask [ True  True False False False]\n",
      "row_args ('A brother is not a',)\n",
      "inputs {'input_ids': tensor([[  32, 3956, 2644]]), 'attention_mask': tensor([[1, 1, 1]])}\n",
      "inputs on device cpu\n",
      "inner model on device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([257.]),\n",
       " array([0.05008946, 0.11171316, 0.04308339, 0.01780186, 0.02406401,\n",
       "        0.02517119, 0.01266759, 0.13250385, 0.03596979, 0.01245437,\n",
       "        0.05560792, 0.00801927, 0.00890699, 0.00555699, 0.03487589,\n",
       "        0.00836223, 0.01562784, 0.01078766, 0.00557194, 0.01027145,\n",
       "        0.00993987, 0.03155802, 0.00900408, 0.01266866, 0.00903098,\n",
       "        0.00592722, 0.01721615, 0.0268929 , 0.01440726, 0.00696987,\n",
       "        0.08031248, 0.01082732, 0.01379489, 0.00812799, 0.00921402,\n",
       "        0.01028549, 0.00534044, 0.00841574, 0.00567698, 0.00522107,\n",
       "        0.00800845, 0.00582852, 0.00572168, 0.00704719, 0.00918054,\n",
       "        0.00510448, 0.00592406, 0.00517234, 0.01058441, 0.00749008],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rmv = fm(~mask.reshape(1, -1))[0]\n",
    "pred_rmv, fm.probs[fm.probs>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_args = np.array(['A brother is not a', 'A girl is not a'])\n",
    "mask = np.array([[False, False, False, True, False], [False, False, True, True, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invariants() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22396/3458769746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/syntax-shap/shap2/utils/_masked_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, masker, link, linearize_link, *args)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# if the masker supports it, save what positions vary from the background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"invariants\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvariants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variants_column_sums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             self._variants_row_inds = [\n",
      "\u001b[0;31mTypeError\u001b[0m: invariants() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "fm = MaskedModel(lmmodel, masker, links.identity, True, *row_args)\n",
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask [False False False  True False]\n",
      "row_args ('A brother is not a',)\n",
      "inputs {'input_ids': tensor([[ 986,  407, 2644]]), 'attention_mask': tensor([[1, 1, 1]])}\n",
      "inputs on device cpu\n",
      "inner model on device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[475.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm(np.array(mask).reshape(1, -1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
